"""
Orchestrateur SharePoint pour l'import automatique des fichiers DPGF
avec monitoring des logs et gestion des erreurs.
"""

import sys
import os
import time
import traceback
import logging
import json
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import requests
from office365.runtime.auth.authentication_context import AuthenticationContext
from office365.sharepoint.client_context import ClientContext
from office365.sharepoint.files.file import File
import pandas as pd
import schedule

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.append(str(Path(__file__).parent))

from app.services.dpgf_import import DPGFImportService
from app.core.config import settings
from app.db.session import SessionLocal

class SharePointOrchestrator:
    """Orchestrateur pour l'import automatique depuis SharePoint"""
    
    def __init__(self, sharepoint_url: str, username: str, password: str):
        self.sharepoint_url = sharepoint_url
        self.username = username
        self.password = password
        self.ctx = None
        self.import_service = DPGFImportService()
        
        # Configuration des logs
        self.setup_logging()
        
        # Statistiques
        self.stats = {
            'files_processed': 0,
            'files_success': 0,
            'files_failed': 0,
            'lots_created': 0,
            'sections_created': 0,
            'elements_created': 0,
            'errors': []
        }
        
    def setup_logging(self):
        """Configuration du syst√®me de logs"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        # Configuration du logger principal
        self.logger = logging.getLogger('sharepoint_orchestrator')
        self.logger.setLevel(logging.DEBUG)
        
        # Handler pour fichier g√©n√©ral
        file_handler = logging.FileHandler(
            log_dir / f"sharepoint_orchestrator_{datetime.now().strftime('%Y%m%d')}.log"
        )
        file_handler.setLevel(logging.DEBUG)
        
        # Handler pour erreurs critiques
        error_handler = logging.FileHandler(
            log_dir / f"sharepoint_errors_{datetime.now().strftime('%Y%m%d')}.log"
        )
        error_handler.setLevel(logging.ERROR)
        
        # Handler pour console
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # Format des logs
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        error_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(error_handler)
        self.logger.addHandler(console_handler)
        
    def connect_sharepoint(self) -> bool:
        """Connexion √† SharePoint"""
        try:
            self.logger.info("üîó Connexion √† SharePoint...")
            auth_ctx = AuthenticationContext(self.sharepoint_url)
            auth_ctx.acquire_token_for_user(self.username, self.password)
            self.ctx = ClientContext(self.sharepoint_url, auth_ctx)
            
            # Test de connexion
            web = self.ctx.web
            self.ctx.load(web)
            self.ctx.execute_query()
            
            self.logger.info(f"‚úÖ Connect√© √† SharePoint: {web.properties['Title']}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur de connexion SharePoint: {str(e)}")
            return False
    
    def get_new_files(self, library_name: str, last_check: datetime = None) -> List[Dict]:
        """R√©cup√®re les nouveaux fichiers DPGF depuis une biblioth√®que SharePoint"""
        try:
            if not last_check:
                last_check = datetime.now() - timedelta(hours=24)
            
            self.logger.info(f"üìÇ Recherche de nouveaux fichiers dans '{library_name}'...")
            
            # Acc√®s √† la biblioth√®que
            doc_lib = self.ctx.web.lists.get_by_title(library_name)
            
            # Requ√™te CAML pour filtrer les fichiers r√©cents
            caml_query = f"""
            <View>
                <Query>
                    <Where>
                        <And>
                            <Geq>
                                <FieldRef Name='Modified'/>
                                <Value Type='DateTime'>{last_check.isoformat()}</Value>
                            </Geq>
                            <Or>
                                <Contains>
                                    <FieldRef Name='FileLeafRef'/>
                                    <Value Type='Text'>.xlsx</Value>
                                </Contains>
                                <Contains>
                                    <FieldRef Name='FileLeafRef'/>
                                    <Value Type='Text'>.xls</Value>
                                </Contains>
                            </Or>
                        </And>
                    </Where>
                </Query>
            </View>
            """
            
            items = doc_lib.get_items(caml_query)
            self.ctx.load(items)
            self.ctx.execute_query()
            
            files_info = []
            for item in items:
                file_info = {
                    'name': item.properties['FileLeafRef'],
                    'url': item.properties['FileRef'],
                    'modified': item.properties['Modified'],
                    'size': item.properties.get('File_x0020_Size', 0),
                    'author': item.properties.get('Author', {}).get('Title', 'Unknown')
                }
                files_info.append(file_info)
            
            self.logger.info(f"üìÑ {len(files_info)} nouveaux fichiers trouv√©s")
            return files_info
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la recherche de fichiers: {str(e)}")
            return []
    
    def download_file(self, file_url: str, local_path: Path) -> bool:
        """T√©l√©charge un fichier depuis SharePoint"""
        try:
            self.logger.info(f"‚¨áÔ∏è T√©l√©chargement: {file_url}")
            
            file_obj = self.ctx.web.get_file_by_server_relative_url(file_url)
            
            with open(local_path, 'wb') as local_file:
                file_obj.download(local_file)
                self.ctx.execute_query()
            
            self.logger.info(f"‚úÖ Fichier t√©l√©charg√©: {local_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur de t√©l√©chargement {file_url}: {str(e)}")
            return False
    
    def process_file(self, file_path: Path, file_info: Dict) -> Dict:
        """Traite un fichier DPGF avec logging d√©taill√©"""
        result = {
            'success': False,
            'file_name': file_info['name'],
            'lots_created': 0,
            'sections_created': 0,
            'elements_created': 0,
            'errors': [],
            'processing_time': 0
        }
        
        start_time = time.time()
        
        try:
            self.logger.info(f"üîÑ Traitement: {file_info['name']}")
            
            # Import du fichier
            with SessionLocal() as db:
                import_result = self.import_service.import_dpgf_file(
                    file_path=str(file_path),
                    db=db
                )
                
                if import_result.get('success', False):
                    result['success'] = True
                    result['lots_created'] = len(import_result.get('lots', []))
                    result['sections_created'] = len(import_result.get('sections', []))
                    result['elements_created'] = len(import_result.get('elements', []))
                    
                    self.logger.info(
                        f"‚úÖ Import r√©ussi: {result['lots_created']} lots, "
                        f"{result['sections_created']} sections, "
                        f"{result['elements_created']} √©l√©ments"
                    )
                    
                    # Mise √† jour des statistiques globales
                    self.stats['lots_created'] += result['lots_created']
                    self.stats['sections_created'] += result['sections_created']
                    self.stats['elements_created'] += result['elements_created']
                    
                else:
                    result['errors'] = import_result.get('errors', ['Erreur inconnue'])
                    self.logger.error(f"‚ùå √âchec import: {result['errors']}")
                    
        except Exception as e:
            error_msg = f"Erreur lors du traitement: {str(e)}"
            result['errors'].append(error_msg)
            self.logger.error(f"‚ùå {error_msg}")
            self.logger.error(traceback.format_exc())
            
        finally:
            result['processing_time'] = time.time() - start_time
            
        return result
    
    def send_notification(self, message: str, level: str = "info"):
        """Envoie une notification (email, Slack, Teams, etc.)"""
        try:
            # Ici vous pouvez impl√©menter vos notifications
            # Exemple avec un webhook Teams/Slack
            webhook_url = os.getenv('NOTIFICATION_WEBHOOK_URL')
            
            if webhook_url:
                payload = {
                    'text': f"[DPGF Orchestrator] {message}",
                    'level': level,
                    'timestamp': datetime.now().isoformat()
                }
                
                response = requests.post(webhook_url, json=payload, timeout=10)
                if response.status_code == 200:
                    self.logger.info("üìß Notification envoy√©e")
                    
        except Exception as e:
            self.logger.error(f"‚ùå Erreur notification: {str(e)}")
    
    def generate_report(self) -> Dict:
        """G√©n√®re un rapport d'ex√©cution"""
        return {
            'timestamp': datetime.now().isoformat(),
            'statistics': self.stats.copy(),
            'success_rate': (
                self.stats['files_success'] / max(self.stats['files_processed'], 1) * 100
            ),
            'total_entities': (
                self.stats['lots_created'] + 
                self.stats['sections_created'] + 
                self.stats['elements_created']
            )
        }
    
    def save_report(self, report: Dict):
        """Sauvegarde le rapport"""
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        report_file = reports_dir / f"sharepoint_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"üìä Rapport sauvegard√©: {report_file}")
    
    def run_import_cycle(self, library_name: str, download_dir: str = "downloads"):
        """Ex√©cute un cycle complet d'import"""
        try:
            self.logger.info("üöÄ D√©marrage du cycle d'import SharePoint")
            
            # Connexion SharePoint
            if not self.connect_sharepoint():
                self.send_notification("√âchec de connexion SharePoint", "error")
                return
            
            # Cr√©ation du dossier de t√©l√©chargement
            download_path = Path(download_dir)
            download_path.mkdir(exist_ok=True)
            
            # R√©cup√©ration des nouveaux fichiers
            last_check = datetime.now() - timedelta(hours=1)  # Derni√®re heure
            new_files = self.get_new_files(library_name, last_check)
            
            if not new_files:
                self.logger.info("üì≠ Aucun nouveau fichier √† traiter")
                return
            
            # Traitement des fichiers
            for file_info in new_files:
                self.stats['files_processed'] += 1
                
                # T√©l√©chargement
                local_file = download_path / file_info['name']
                if not self.download_file(file_info['url'], local_file):
                    self.stats['files_failed'] += 1
                    continue
                
                # Traitement
                result = self.process_file(local_file, file_info)
                
                if result['success']:
                    self.stats['files_success'] += 1
                    self.logger.info(f"‚úÖ Fichier trait√© avec succ√®s: {file_info['name']}")
                else:
                    self.stats['files_failed'] += 1
                    self.stats['errors'].extend(result['errors'])
                    self.logger.error(f"‚ùå √âchec traitement: {file_info['name']}")
                
                # Nettoyage du fichier temporaire
                try:
                    local_file.unlink()
                except:
                    pass
            
            # G√©n√©ration du rapport
            report = self.generate_report()
            self.save_report(report)
            
            # Notification de fin
            summary = (
                f"Cycle termin√©: {self.stats['files_success']}/{self.stats['files_processed']} "
                f"fichiers trait√©s avec succ√®s. "
                f"Entit√©s cr√©√©es: {report['total_entities']}"
            )
            
            self.logger.info(f"üéØ {summary}")
            self.send_notification(summary)
            
        except Exception as e:
            error_msg = f"Erreur critique dans le cycle d'import: {str(e)}"
            self.logger.error(error_msg)
            self.logger.error(traceback.format_exc())
            self.send_notification(error_msg, "error")


def main():
    """Fonction principale pour l'orchestrateur"""
    
    # Configuration SharePoint (√† adapter selon votre environnement)
    SHAREPOINT_URL = os.getenv('SHAREPOINT_URL', 'https://votreentreprise.sharepoint.com/sites/votresite')
    SHAREPOINT_USERNAME = os.getenv('SHAREPOINT_USERNAME')
    SHAREPOINT_PASSWORD = os.getenv('SHAREPOINT_PASSWORD')
    LIBRARY_NAME = os.getenv('SHAREPOINT_LIBRARY', 'Documents DPGF')
    
    if not SHAREPOINT_USERNAME or not SHAREPOINT_PASSWORD:
        print("‚ùå Erreur: Variables d'environnement SharePoint manquantes")
        print("D√©finissez SHAREPOINT_USERNAME et SHAREPOINT_PASSWORD")
        return
    
    # Cr√©ation de l'orchestrateur
    orchestrator = SharePointOrchestrator(
        sharepoint_url=SHAREPOINT_URL,
        username=SHAREPOINT_USERNAME,
        password=SHAREPOINT_PASSWORD
    )
    
    # Mode d'ex√©cution
    mode = sys.argv[1] if len(sys.argv) > 1 else 'once'
    
    if mode == 'once':
        # Ex√©cution unique
        print("üîÑ Ex√©cution unique de l'orchestrateur...")
        orchestrator.run_import_cycle(LIBRARY_NAME)
        
    elif mode == 'scheduled':
        # Ex√©cution planifi√©e
        print("‚è∞ D√©marrage de l'orchestrateur en mode planifi√©...")
        
        # Planification (toutes les heures)
        schedule.every().hour.do(orchestrator.run_import_cycle, LIBRARY_NAME)
        
        # Planification quotidienne √† 8h pour rapport complet
        schedule.every().day.at("08:00").do(
            lambda: orchestrator.send_notification("Rapport quotidien disponible")
        )
        
        print("‚è∞ Planification active. Ctrl+C pour arr√™ter.")
        
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # V√©rification chaque minute
                
        except KeyboardInterrupt:
            print("\nüõë Arr√™t de l'orchestrateur planifi√©")
            
    elif mode == 'monitor':
        # Mode monitoring en continu
        print("üëÅÔ∏è D√©marrage du monitoring en continu...")
        
        try:
            while True:
                orchestrator.run_import_cycle(LIBRARY_NAME)
                print("üò¥ Attente 10 minutes avant le prochain cycle...")
                time.sleep(600)  # 10 minutes
                
        except KeyboardInterrupt:
            print("\nüõë Arr√™t du monitoring")
    
    else:
        print("‚ùå Mode invalide. Utilisez: 'once', 'scheduled', ou 'monitor'")


if __name__ == "__main__":
    main()
