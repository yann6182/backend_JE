#!/usr/bin/env python3
"""
Script de test rapide optimisÃ© pour identifier des fichiers DPGF dans des dossiers 
SharePoint avec gestion amÃ©liorÃ©e des grands dossiers et des timeouts.
"""

import subprocess
import sys
import os
import logging
import time
import json
from pathlib import Path
from typing import List, Dict, Optional, Any
import requests

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.FileHandler("quick_test_logs.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def test_specific_folders():
    """Teste quelques dossiers spÃ©cifiques rÃ©cents"""
    
    # Dossiers rÃ©cents qui ont plus de chances de contenir des DPGF
    test_folders = [
        "/06-27-2025-BOULOGNE-BILLANCOURT - CONSTRUCTION MAISON REPIT VNO",
        "/06-27-2025-I3F-PARIS-REHA_BALCONS_GARDE_COPRS", 
        "/07-04-2025-BOIS_COLOMBES-HALLE_DE_MARCHE VNO",
        "/07-04-2025-CHAMARANDE- CONSTRUCTION-14LGT VNO"
    ]
    
    print("ðŸ” Test rapide de dossiers spÃ©cifiques rÃ©cents...")
    print("=" * 50)
    
    all_identified_files = []
    
    for folder in test_folders:
        print(f"\nðŸ“ Test du dossier: {folder}")
        print("-" * 40)
        
        # Approche en deux phases:
        # 1. VÃ©rification rapide avec Ã©chantillonnage pour estimer le volume
        # 2. Analyse complÃ¨te avec pagination si nÃ©cessaire
        
        try:
            # Phase 1: Ã‰chantillonnage rapide avec --summary et --max-files
            print("ðŸ”„ Phase 1: Ã‰chantillonnage rapide...")
            cmd_sample = [
                sys.executable, 
                "scripts/identify_relevant_files_sharepoint.py",
                "--source", "sharepoint",
                "--folder", folder,
                "--mode", "summary",  # Mode sommaire pour estimer le volume
                "--max-files", "10",
                "--quiet",
                "--output-format", "json"
            ]
            
            result_sample = subprocess.run(
                cmd_sample, 
                capture_output=True, 
                text=True, 
                encoding='utf-8',
                errors='replace',
                timeout=60  # 60 secondes max pour l'Ã©chantillonnage
            )
            
            # Analyser le rÃ©sultat de l'Ã©chantillonnage
            folder_size = None
            if result_sample.returncode == 0:
                try:
                    # Essayer de parser le JSON de sortie
                    output_lines = result_sample.stdout.strip().split('\n')
                    for line in output_lines:
                        if line.startswith('{') and line.endswith('}'):
                            data = json.loads(line)
                            if 'total_files' in data:
                                folder_size = data.get('total_files', 0)
                                print(f"ðŸ“Š Estimation: environ {folder_size} fichiers dans ce dossier")
                                
                                # VÃ©rifier les rÃ©sultats prÃ©liminaires
                                relevant_count = data.get('potential_dpgf_count', 0) + data.get('potential_bpu_count', 0) + data.get('potential_dqe_count', 0)
                                if relevant_count > 0:
                                    print(f"âœ… DÃ©tectÃ© ~{relevant_count} fichiers potentiellement pertinents dans l'Ã©chantillon")
                                else:
                                    print("âš ï¸ Aucun fichier pertinent dÃ©tectÃ© dans l'Ã©chantillon")
                except json.JSONDecodeError:
                    pass
            
            # Phase 2: Analyse complÃ¨te avec pagination si nÃ©cessaire
            print("ðŸ”„ Phase 2: Analyse dÃ©taillÃ©e...")
            
            # Ajuster les paramÃ¨tres en fonction de la taille du dossier
            max_files = 5
            timeout_value = 180  # 3 minutes par dÃ©faut
            
            if folder_size:
                if folder_size > 1000:
                    max_files = 3
                    timeout_value = 300  # 5 minutes pour les trÃ¨s grands dossiers
                elif folder_size > 500:
                    max_files = 5
                    timeout_value = 240  # 4 minutes pour les grands dossiers
                elif folder_size > 100:
                    max_files = 10
                    timeout_value = 180  # 3 minutes pour les dossiers moyens
            
            # GÃ©nÃ©rer un nom de fichier de sortie unique pour cette analyse
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_basename = f"quick_test_{timestamp}_{folder.replace('/', '_').replace(' ', '_')[:30]}"
            
            cmd = [
                sys.executable, 
                "scripts/identify_relevant_files_sharepoint.py",
                "--source", "sharepoint",
                "--folder", folder,
                "--mode", "quick", 
                "--max-files", str(max_files),
                "--min-confidence", "0.1",
                "--formats", "txt,json",  # Sortie dans les deux formats
                "--output-basename", output_basename
            ]
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                encoding='utf-8',
                errors='replace',
                timeout=timeout_value
            )
            
            # Analyser le rÃ©sultat
            if result.returncode == 0:
                # Essayer de lire le fichier JSON de rÃ©sultats
                json_report_path = f"reports/{output_basename}.json"
                if os.path.exists(json_report_path):
                    try:
                        with open(json_report_path, 'r', encoding='utf-8') as f:
                            report_data = json.load(f)
                            
                        identified_files = report_data.get('identified_files', [])
                        if identified_files:
                            print(f"âœ… {len(identified_files)} fichiers DPGF trouvÃ©s dans ce dossier !")
                            for file_info in identified_files[:3]:  # Afficher les 3 premiers
                                print(f"   - {file_info.get('name')} (Score: {file_info.get('confidence', 0):.2f})")
                            if len(identified_files) > 3:
                                print(f"   - ... et {len(identified_files)-3} autres fichiers")
                        else:
                            print("âŒ Aucun fichier DPGF identifiÃ©")
                    except (json.JSONDecodeError, FileNotFoundError) as e:
                        print(f"âš ï¸ Erreur lors de la lecture du rapport JSON: {str(e)}")
                        # Fallback sur l'analyse de la sortie texte
                        output = result.stdout
                        if "fichiers identifiÃ©s" in output and "0 fichiers identifiÃ©s" not in output:
                            print("âœ… Fichiers DPGF trouvÃ©s dans ce dossier !")
                            # Extraire les dÃ©tails
                            for line in output.split('\n'):
                                if "fichiers identifiÃ©s" in line:
                                    print(f"   {line.strip()}")
                        else:
                            print("âŒ Aucun fichier DPGF identifiÃ©")
            else:
                print(f"âš ï¸ Erreur: {result.stderr[:200]}...")
                
        except subprocess.TimeoutExpired:
            print("â° Timeout - dossier trop volumineux")
            print("   Essayez avec une analyse plus ciblÃ©e ou utilisez l'orchestrateur.")
        except Exception as e:
            print(f"âŒ Erreur: {str(e)}")
    
    print(f"\n{'='*50}")
    print("âœ… Test rapide terminÃ© !")
    print("\nPour lancer l'analyse complÃ¨te optimisÃ©e:")
    print("python orchestrate_dpgf_workflow.py --interactive --max-files 30")

def test_specific_folder(folder_path: str, max_files: int = 5):
    """Teste un dossier spÃ©cifique avec gestion optimisÃ©e des grands dossiers"""
    
    print(f"\nðŸ“ Test du dossier: {folder_path}")
    print("-" * 40)
    
    try:
        # GÃ©nÃ©rer un nom de fichier de sortie unique
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_basename = f"quick_test_{timestamp}"
        
        # Ã‰chantillonnage rapide avec --summary
        print("ðŸ”„ Ã‰chantillonnage rapide...")
        cmd_sample = [
            sys.executable, 
            "scripts/identify_relevant_files_sharepoint.py",
            "--source", "sharepoint",
            "--folder", folder_path,
            "--mode", "summary",
            "--output-format", "json"
        ]
        
        sample_result = subprocess.run(
            cmd_sample, 
            capture_output=True, 
            text=True, 
            encoding='utf-8',
            errors='replace',
            timeout=60
        )
        
        estimated_size = 0
        if sample_result.returncode == 0:
            try:
                # Analyser la sortie JSON
                output_lines = sample_result.stdout.strip().split('\n')
                for line in output_lines:
                    if line.startswith('{') and line.endswith('}'):
                        data = json.loads(line)
                        estimated_size = data.get('total_files', 0)
                        print(f"ðŸ“Š Estimation: environ {estimated_size} fichiers")
            except json.JSONDecodeError:
                pass
        
        # Ajuster les paramÃ¨tres en fonction de la taille estimÃ©e
        adjusted_max_files = max_files
        timeout_value = 240  # 4 minutes par dÃ©faut
        
        if estimated_size > 1000:
            adjusted_max_files = min(max_files, 3)
            timeout_value = 300  # 5 minutes pour trÃ¨s grands dossiers
        elif estimated_size > 500:
            adjusted_max_files = min(max_files, 5)
            timeout_value = 240
        
        print(f"ðŸ”„ Analyse avec max_files={adjusted_max_files}, timeout={timeout_value}s...")
        
        # ExÃ©cuter l'analyse complÃ¨te
        cmd = [
            sys.executable, 
            "scripts/identify_relevant_files_sharepoint.py",
            "--source", "sharepoint",
            "--folder", folder_path,
            "--mode", "quick", 
            "--max-files", str(adjusted_max_files),
            "--min-confidence", "0.2",
            "--formats", "txt,json",
            "--output-basename", output_basename
        ]
        
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True, 
            encoding='utf-8',
            errors='replace',
            timeout=timeout_value
        )
        
        # Analyser le rÃ©sultat
        if result.returncode == 0:
            # Chercher le fichier de rapport JSON
            json_report_path = f"reports/{output_basename}.json"
            if os.path.exists(json_report_path):
                try:
                    with open(json_report_path, 'r', encoding='utf-8') as f:
                        report_data = json.load(f)
                    
                    identified_files = report_data.get('identified_files', [])
                    total_scanned = report_data.get('total_files_scanned', 0)
                    
                    print(f"ðŸ“Š {total_scanned} fichiers analysÃ©s")
                    
                    if identified_files:
                        print(f"âœ… {len(identified_files)} fichiers pertinents trouvÃ©s:")
                        for idx, file_info in enumerate(identified_files[:5]):
                            print(f"   {idx+1}. {file_info.get('name')} (Score: {file_info.get('confidence', 0):.2f})")
                        if len(identified_files) > 5:
                            print(f"   ... et {len(identified_files)-5} autres fichiers")
                            
                        # Optionnel: afficher le chemin vers le rapport complet
                        txt_report_path = f"reports/{output_basename}.txt"
                        if os.path.exists(txt_report_path):
                            print(f"\nðŸ“ Rapport complet: {txt_report_path}")
                    else:
                        print("âŒ Aucun fichier pertinent identifiÃ©")
                        
                    return identified_files
                    
                except (json.JSONDecodeError, FileNotFoundError) as e:
                    print(f"âš ï¸ Erreur lecture rapport: {str(e)}")
            else:
                print("âš ï¸ Rapport JSON non trouvÃ©, analyse de la sortie texte...")
                output = result.stdout
                if "fichiers identifiÃ©s" in output and "0 fichiers identifiÃ©s" not in output:
                    print("âœ… Fichiers pertinents trouvÃ©s!")
                    for line in output.split('\n'):
                        if "fichiers identifiÃ©s" in line:
                            print(f"   {line.strip()}")
                else:
                    print("âŒ Aucun fichier pertinent identifiÃ©")
        else:
            print(f"âš ï¸ Erreur: {result.stderr[:200]}...")
            
    except subprocess.TimeoutExpired:
        print("â° Timeout - Le dossier est trop volumineux")
        print("   Recommandations:")
        print("   1. Utiliser un sous-dossier plus spÃ©cifique")
        print("   2. Augmenter le timeout ou rÃ©duire max_files")
        print("   3. Utiliser l'orchestrateur pour traitement par lots")
    except Exception as e:
        print(f"âŒ Erreur inattendue: {str(e)}")
    
    return []

def test_with_retry(folder_path: str, max_files: int = 5, max_retries: int = 2):
    """Teste un dossier avec systÃ¨me de retry en cas d'erreur rÃ©seau"""
    for attempt in range(max_retries + 1):
        try:
            if attempt > 0:
                print(f"\nðŸ”„ Tentative {attempt+1}/{max_retries+1}...")
                time.sleep(3)  # Attendre un peu entre les tentatives
            return test_specific_folder(folder_path, max_files)
        except (requests.exceptions.RequestException, ConnectionError) as e:
            if attempt < max_retries:
                print(f"âš ï¸ Erreur rÃ©seau: {str(e)}")
                print("   Nouvelle tentative dans quelques secondes...")
            else:
                print(f"âŒ Ã‰chec aprÃ¨s {max_retries+1} tentatives: {str(e)}")
                return []

def print_help():
    """Affiche l'aide du script"""
    print("""
Usage: python test_quick_dpgf_optimized.py [OPTIONS] [FOLDER]

Options:
  --max-files N     Nombre maximum de fichiers Ã  analyser par dossier (dÃ©faut: 5)
  --retries N       Nombre maximum de tentatives en cas d'erreur rÃ©seau (dÃ©faut: 2)
  --predefined      Tester les dossiers prÃ©dÃ©finis (comportement par dÃ©faut)
  --help            Afficher cette aide
  
Exemples:
  python test_quick_dpgf_optimized.py
  python test_quick_dpgf_optimized.py "/07-04-2025-BOIS_COLOMBES-HALLE_DE_MARCHE VNO"
  python test_quick_dpgf_optimized.py --max-files 10 "/Projets importants/DPGF"
    """)

if __name__ == "__main__":
    # Traiter les arguments
    import argparse
    
    parser = argparse.ArgumentParser(description="Test rapide optimisÃ© des dossiers SharePoint")
    parser.add_argument("folder", nargs="?", help="Dossier SharePoint Ã  tester")
    parser.add_argument("--max-files", type=int, default=5, help="Nombre max de fichiers Ã  analyser")
    parser.add_argument("--retries", type=int, default=2, help="Nombre de tentatives en cas d'erreur")
    parser.add_argument("--predefined", action="store_true", help="Tester les dossiers prÃ©dÃ©finis")
    parser.add_argument("--show-help", action="store_true", help="Afficher l'aide")
    
    args = parser.parse_args()
    
    if args.show_help:
        print_help()
        sys.exit(0)
    
    if not args.folder and not args.predefined:
        # Par dÃ©faut, tester les dossiers prÃ©dÃ©finis
        test_specific_folders()
    elif args.folder:
        print(f"\nðŸ” Test du dossier SharePoint: {args.folder}")
        test_with_retry(args.folder, args.max_files, args.retries)
    else:  # args.predefined
        test_specific_folders()
