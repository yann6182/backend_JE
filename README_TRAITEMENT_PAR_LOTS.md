# Guide du traitement par lots DPGF

## Vue d'ensemble

Le nouveau systÃ¨me de traitement par lots permet de gÃ©rer efficacement de gros volumes de fichiers DPGF sans surcharger le systÃ¨me de stockage local. Au lieu de tÃ©lÃ©charger tous les fichiers d'un coup, le workflow procÃ¨de par petits lots successifs avec nettoyage automatique.

## Principe de fonctionnement

```mermaid
graph TD
    A[Identification SharePoint] --> B[Liste des fichiers pertinents]
    B --> C[Division en lots de N fichiers]
    C --> D[Lot 1: TÃ©lÃ©chargement]
    D --> E[Lot 1: Import en base]
    E --> F[Lot 1: Nettoyage automatique]
    F --> G[Lot 2: TÃ©lÃ©chargement]
    G --> H[Lot 2: Import en base]
    H --> I[Lot 2: Nettoyage automatique]
    I --> J[... Lots suivants]
    J --> K[Rapport final]
```

## Avantages

### ğŸš€ Gestion mÃ©moire optimisÃ©e
- **Stockage minimal** : Seuls 10-20 fichiers stockÃ©s localement Ã  la fois
- **Ã‰vite la saturation** : Pas de tÃ©lÃ©chargement massif de centaines de GB
- **Nettoyage auto** : Suppression immÃ©diate aprÃ¨s import rÃ©ussi

### ğŸ”„ Processus robuste
- **RÃ©cupÃ©ration partielle** : Ã‰chec d'un lot n'arrÃªte pas le processus
- **TraÃ§abilitÃ©** : Logs dÃ©taillÃ©s par lot
- **Reprise possible** : Peut reprendre au lot suivant en cas d'interruption

### ğŸ“Š ContrÃ´le prÃ©cis
- **Taille configurable** : Lots de 5 Ã  50 fichiers selon les besoins
- **PrioritÃ©** : Traitement par ordre de confiance dÃ©croissante
- **Monitoring** : Progression lot par lot avec statistiques

## Configuration

### ParamÃ¨tres principaux

```json
{
  "scanning": {
    "batch_size": 10,           // Taille des lots (recommandÃ©: 5-20)
    "max_files": 100,           // Total max de fichiers
    "min_confidence": 0.5       // Confiance minimum
  },
  "download": {
    "batch_processing": true,   // Activer le traitement par lots
    "auto_cleanup": true,       // Nettoyage automatique
    "max_batch_size_mb": 100    // Taille max d'un lot en MB
  }
}
```

### Tailles de lots recommandÃ©es

| Volume total | Taille de lot | Raison |
|--------------|---------------|---------|
| < 50 fichiers | 10 fichiers | Ã‰quilibre performance/mÃ©moire |
| 50-200 fichiers | 15 fichiers | Optimisation des transferts |
| > 200 fichiers | 20 fichiers | Maximum d'efficacitÃ© |

## Utilisation

### Via l'interface batch
```bash
# Lancer l'interface
run_dpgf_workflow.bat

# Choisir option 1 (Workflow automatique)
# Le systÃ¨me utilise automatiquement des lots de 10 fichiers
```

### Via la ligne de commande
```bash
# Workflow avec lots personnalisÃ©s
python orchestrate_dpgf_workflow.py --auto \
    --batch-size 15 \
    --max-files 100 \
    --auto-cleanup

# Workflow interactif avec confirmation par lot
python orchestrate_dpgf_workflow.py --interactive \
    --batch-size 10 \
    --min-confidence 0.7
```

### Configuration personnalisÃ©e
```bash
# Gros volumes avec petits lots
python orchestrate_dpgf_workflow.py --auto \
    --batch-size 5 \
    --max-files 500 \
    --min-confidence 0.8

# Traitement rapide avec gros lots
python orchestrate_dpgf_workflow.py --auto \
    --batch-size 25 \
    --max-files 100 \
    --min-confidence 0.3
```

## Monitoring du processus

### Structure des rÃ©pertoires
```
dpgf_workflow/
â”œâ”€â”€ downloaded_files/
â”‚   â”œâ”€â”€ batch_0/              # Lot en cours de traitement
â”‚   â”‚   â”œâ”€â”€ DPGF_file1.xlsx
â”‚   â”‚   â””â”€â”€ batch_0_info.json
â”‚   â””â”€â”€ batch_1/              # Sera supprimÃ© aprÃ¨s import
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ workflow_report_xxx.txt
â””â”€â”€ logs/
    â”œâ”€â”€ orchestration_dpgf.log
    â””â”€â”€ batch_processing.log
```

### Exemple de progression
```
ğŸ”„ Traitement de 47 fichiers en 5 lots de 10 fichiers

ğŸ“¦ Lot 1/5: Traitement de 10 fichiers
â¬‡ï¸ TÃ©lÃ©chargement du lot 1...
âœ… Lot 1 tÃ©lÃ©chargÃ©: 10 fichiers (85.2 MB)
ğŸ“Š Import du lot 1 en base de donnÃ©es...
ğŸ“Š Lot 1 importÃ©: 9/10 fichiers rÃ©ussis
ğŸ§¹ Lot 1 nettoyÃ©: 85.2 MB libÃ©rÃ©s

ğŸ“¦ Lot 2/5: Traitement de 10 fichiers
â¬‡ï¸ TÃ©lÃ©chargement du lot 2...
âœ… Lot 2 tÃ©lÃ©chargÃ©: 10 fichiers (92.1 MB)
...
```

## Gestion des erreurs

### Erreurs non-critiques (continuent)
- **Ã‰chec tÃ©lÃ©chargement** d'un fichier spÃ©cifique â†’ Skip et continue
- **Erreur import** d'un fichier â†’ Import des autres du lot
- **Timeout rÃ©seau** â†’ Retry automatique

### Erreurs critiques (arrÃªt)
- **Ã‰chec authentification** SharePoint
- **API backend** inaccessible
- **Espace disque** insuffisant

### RÃ©cupÃ©ration d'erreurs
```bash
# Reprendre aprÃ¨s interruption
python orchestrate_dpgf_workflow.py --auto \
    --batch-size 10 \
    --resume-from-batch 3  # Reprendre au lot 3
```

## Optimisations par contexte

### Environnement limitÃ© en espace
```bash
# TrÃ¨s petits lots avec nettoyage agressif
python orchestrate_dpgf_workflow.py --auto \
    --batch-size 5 \
    --auto-cleanup \
    --max-files 50
```

### Connexion rÃ©seau lente
```bash
# Lots plus petits, moins de timeouts
python orchestrate_dpgf_workflow.py --auto \
    --batch-size 8 \
    --deep-scan false \  # Plus rapide
    --max-files 40
```

### Traitement de nuit automatisÃ©
```bash
# Lots moyens avec gestion d'erreurs robuste
python orchestrate_dpgf_workflow.py --auto \
    --batch-size 15 \
    --max-files 200 \
    --min-confidence 0.6 \
    --auto-cleanup
```

## Scripts de maintenance

### Nettoyage manuel
```bash
# Supprimer tous les fichiers temporaires
python -c "
import shutil
from pathlib import Path
if Path('dpgf_workflow/downloaded_files').exists():
    shutil.rmtree('dpgf_workflow/downloaded_files')
    print('ğŸ§¹ Fichiers temporaires supprimÃ©s')
"
```

### VÃ©rification de l'espace disque
```bash
# VÃ©rifier l'espace avant traitement
python -c "
import shutil
free_gb = shutil.disk_usage('.').free / (1024**3)
print(f'ğŸ’¾ Espace libre: {free_gb:.1f} GB')
if free_gb < 5:
    print('âš ï¸ Espace insuffisant - utilisez des lots plus petits')
"
```

### Estimation de la durÃ©e
```bash
# Estimer le temps total
python -c "
files = 100  # Nombre de fichiers
batch_size = 10
avg_time_per_batch = 5  # minutes
total_time = (files / batch_size) * avg_time_per_batch
print(f'â±ï¸ Temps estimÃ©: {total_time:.0f} minutes')
"
```

## Surveillance automatique

### Script de monitoring
```python
# monitor_workflow.py
import time
import json
from pathlib import Path

def monitor_progress():
    """Surveille la progression du workflow"""
    while True:
        try:
            # Lire les logs d'orchestration
            log_file = Path('dpgf_workflow/logs/orchestration_dpgf.log')
            if log_file.exists():
                with open(log_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    # Analyser la progression
                    for line in reversed(lines[-10:]):
                        if "Lot" in line and "terminÃ©" in line:
                            print(f"ğŸ“Š {line.strip()}")
                            break
            
            time.sleep(30)  # VÃ©rifier toutes les 30 secondes
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"Erreur monitoring: {e}")
            time.sleep(60)

if __name__ == "__main__":
    monitor_progress()
```

### Alertes par email (optionnel)
```python
# Configuration dans workflow_config.json
{
  "notifications": {
    "email": {
      "enabled": true,
      "on_batch_complete": true,
      "on_error": true,
      "recipients": ["admin@company.com"]
    }
  }
}
```

## Bonnes pratiques

### ğŸ’¡ Recommandations gÃ©nÃ©rales
1. **Commencer petit** : Test avec 1-2 lots avant le traitement complet
2. **Surveiller l'espace** : VÃ©rifier l'espace disque disponible
3. **Horaires optimaux** : Lancer pendant les heures creuses
4. **Sauvegarde** : Backup de la base avant gros imports

### ğŸš¨ Erreurs Ã  Ã©viter
1. **Lots trop gros** : > 50 fichiers â†’ risque de timeout
2. **Pas de nettoyage** : Saturation du disque
3. **Confiance trop basse** : Import de fichiers non pertinents
4. **Interruption manuelle** : Laisser le processus se terminer

### ğŸ¯ Optimisations
1. **Trier par taille** : Petits fichiers en premier
2. **Filtrage strict** : Confiance â‰¥ 0.5 pour production
3. **Monitoring actif** : Surveiller les logs en temps rÃ©el
4. **Tests rÃ©guliers** : Valider les imports en base

Le traitement par lots transforme la gestion de gros volumes DPGF en un processus maÃ®trisÃ© et efficace ! ğŸš€
