#!/usr/bin/env python3
"""
Analyse d√©taill√©e d'un fichier DPGF sp√©cifique.
Permet de comprendre pourquoi un fichier identifi√© comme DPGF ne produit pas de donn√©es.
"""

import os
import sys
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import openpyxl
from openpyxl.utils import get_column_letter

# Ajouter le r√©pertoire scripts au path
scripts_dir = Path(__file__).parent / "scripts"
if scripts_dir.exists():
    sys.path.insert(0, str(scripts_dir))

class DPGFFileAnalyzer:
    """Analyseur d√©taill√© d'un fichier DPGF"""
    
    def __init__(self, file_path: str):
        """
        Initialise l'analyseur
        
        Args:
            file_path: Chemin vers le fichier DPGF √† analyser
        """
        self.file_path = Path(file_path)
        if not self.file_path.exists():
            raise FileNotFoundError(f"Fichier non trouv√©: {file_path}")
        
        self.workbook = None
        self.sheets_info = {}
        self.analysis_results = {}
    
    def load_file(self):
        """Charge le fichier Excel"""
        try:
            self.workbook = openpyxl.load_workbook(self.file_path, data_only=True)
            print(f"‚úÖ Fichier charg√©: {self.file_path.name}")
            print(f"üìä Feuilles trouv√©es: {len(self.workbook.sheetnames)}")
            
            for sheet_name in self.workbook.sheetnames:
                sheet = self.workbook[sheet_name]
                self.sheets_info[sheet_name] = {
                    'max_row': sheet.max_row,
                    'max_column': sheet.max_column,
                    'has_data': sheet.max_row > 1 or sheet.max_column > 1
                }
                print(f"   ‚Ä¢ {sheet_name}: {sheet.max_row} lignes √ó {sheet.max_column} colonnes")
            
        except Exception as e:
            raise Exception(f"Erreur lors du chargement: {e}")
    
    def detect_dpgf_patterns(self, sheet_name: str = None) -> Dict:
        """
        D√©tecte les patterns DPGF dans une feuille
        
        Args:
            sheet_name: Nom de la feuille (premi√®re feuille si None)
            
        Returns:
            Dict: Patterns d√©tect√©s
        """
        if not self.workbook:
            self.load_file()
        
        if sheet_name is None:
            sheet_name = self.workbook.sheetnames[0]
        
        sheet = self.workbook[sheet_name]
        
        patterns = {
            'lot_indicators': [],
            'section_indicators': [],
            'price_columns': [],
            'unit_columns': [],
            'quantity_columns': [],
            'designation_columns': [],
            'total_indicators': [],
            'structure_analysis': {
                'has_headers': False,
                'header_row': None,
                'data_starts_at': None,
                'potential_lot_rows': [],
                'potential_section_rows': [],
                'potential_element_rows': []
            }
        }
        
        # Mots-cl√©s DPGF
        lot_keywords = [
            'lot', 'tranche', 'phase', 'ouvrage', 'corps', '√©tat',
            'travaux', 'march√©', 'sous-traitance'
        ]
        
        section_keywords = [
            'chapitre', 'sous-chapitre', 'section', 'sous-section',
            'titre', 'sous-titre', 'poste', 'sous-poste'
        ]
        
        price_keywords = [
            'prix', 'montant', 'co√ªt', 'tarif', 'pu', 'p.u',
            'unitaire', 'total', 'ht', 'ttc'
        ]
        
        unit_keywords = [
            'unit√©', 'u', 'unite', 'mesure', 'ml', 'm¬≤', 'm3',
            'kg', 'tonnes', 'forfait', 'ens', 'nb', 'pcs'
        ]
        
        quantity_keywords = [
            'quantit√©', 'qte', 'quantite', 'nombre', 'nb',
            'm√©tr√©', 'metre', 'volume', 'surface'
        ]
        
        # Analyser chaque ligne
        for row_idx in range(1, min(sheet.max_row + 1, 200)):  # Limiter √† 200 lignes pour la performance
            row_data = []
            has_content = False
            
            for col_idx in range(1, min(sheet.max_column + 1, 20)):  # Limiter √† 20 colonnes
                cell = sheet.cell(row=row_idx, column=col_idx)
                value = cell.value
                
                if value is not None:
                    has_content = True
                    row_data.append(str(value).strip())
                else:
                    row_data.append("")
            
            if not has_content:
                continue
            
            # Analyser le contenu de la ligne
            row_text = " ".join(row_data).lower()
            
            # D√©tecter les indicateurs de lot
            for keyword in lot_keywords:
                if keyword in row_text and len(row_text) < 200:  # √âviter les lignes trop longues
                    patterns['lot_indicators'].append({
                        'row': row_idx,
                        'keyword': keyword,
                        'content': row_text[:100],
                        'columns_with_data': [i for i, val in enumerate(row_data) if val]
                    })
                    patterns['structure_analysis']['potential_lot_rows'].append(row_idx)
                    break
            
            # D√©tecter les indicateurs de section
            for keyword in section_keywords:
                if keyword in row_text and len(row_text) < 200:
                    patterns['section_indicators'].append({
                        'row': row_idx,
                        'keyword': keyword,
                        'content': row_text[:100],
                        'columns_with_data': [i for i, val in enumerate(row_data) if val]
                    })
                    patterns['structure_analysis']['potential_section_rows'].append(row_idx)
                    break
            
            # D√©tecter les colonnes de prix/unit√©/quantit√© dans les en-t√™tes
            if row_idx <= 10:  # Chercher dans les 10 premi√®res lignes
                for col_idx, cell_value in enumerate(row_data):
                    if cell_value:
                        cell_lower = cell_value.lower()
                        
                        # Colonnes de prix
                        if any(keyword in cell_lower for keyword in price_keywords):
                            patterns['price_columns'].append({
                                'column': col_idx + 1,
                                'header': cell_value,
                                'row': row_idx
                            })
                        
                        # Colonnes d'unit√©
                        if any(keyword in cell_lower for keyword in unit_keywords):
                            patterns['unit_columns'].append({
                                'column': col_idx + 1,
                                'header': cell_value,
                                'row': row_idx
                            })
                        
                        # Colonnes de quantit√©
                        if any(keyword in cell_lower for keyword in quantity_keywords):
                            patterns['quantity_columns'].append({
                                'column': col_idx + 1,
                                'header': cell_value,
                                'row': row_idx
                            })
            
            # D√©tecter les √©l√©ments potentiels (lignes avec prix et unit√©)
            numeric_values = []
            for cell_value in row_data:
                try:
                    if cell_value and cell_value.replace(',', '.').replace(' ', '').replace('‚Ç¨', '').isdigit():
                        numeric_values.append(float(cell_value.replace(',', '.').replace(' ', '').replace('‚Ç¨', '')))
                except:
                    pass
            
            if len(numeric_values) >= 2 and len(row_text) > 10:  # Au moins 2 valeurs num√©riques et du texte
                patterns['structure_analysis']['potential_element_rows'].append({
                    'row': row_idx,
                    'numeric_count': len(numeric_values),
                    'content_length': len(row_text),
                    'content_preview': row_text[:50]
                })
        
        # Analyser la structure g√©n√©rale
        if patterns['price_columns'] or patterns['unit_columns']:
            patterns['structure_analysis']['has_headers'] = True
            header_rows = []
            for col_info in patterns['price_columns'] + patterns['unit_columns']:
                header_rows.append(col_info['row'])
            if header_rows:
                patterns['structure_analysis']['header_row'] = min(header_rows)
                patterns['structure_analysis']['data_starts_at'] = min(header_rows) + 1
        
        return patterns
    
    def analyze_file_structure(self) -> Dict:
        """Analyse compl√®te de la structure du fichier"""
        if not self.workbook:
            self.load_file()
        
        analysis = {
            'file_info': {
                'name': self.file_path.name,
                'size': self.file_path.stat().st_size,
                'sheets_count': len(self.workbook.sheetnames),
                'sheets': list(self.workbook.sheetnames)
            },
            'dpgf_compatibility': {
                'score': 0.0,
                'reasons': [],
                'missing_elements': [],
                'detected_elements': []
            },
            'sheets_analysis': {}
        }
        
        total_score = 0
        max_score = 100
        
        # Analyser chaque feuille
        for sheet_name in self.workbook.sheetnames:
            patterns = self.detect_dpgf_patterns(sheet_name)
            analysis['sheets_analysis'][sheet_name] = patterns
            
            # Calculer le score de compatibilit√© DPGF
            sheet_score = 0
            
            # Points pour les indicateurs de structure
            if patterns['lot_indicators']:
                sheet_score += 25
                analysis['dpgf_compatibility']['detected_elements'].append(f"Lots d√©tect√©s ({len(patterns['lot_indicators'])})")
            else:
                analysis['dpgf_compatibility']['missing_elements'].append("Aucun lot d√©tect√©")
            
            if patterns['section_indicators']:
                sheet_score += 20
                analysis['dpgf_compatibility']['detected_elements'].append(f"Sections d√©tect√©es ({len(patterns['section_indicators'])})")
            else:
                analysis['dpgf_compatibility']['missing_elements'].append("Aucune section d√©tect√©e")
            
            if patterns['price_columns']:
                sheet_score += 20
                analysis['dpgf_compatibility']['detected_elements'].append(f"Colonnes de prix ({len(patterns['price_columns'])})")
            else:
                analysis['dpgf_compatibility']['missing_elements'].append("Aucune colonne de prix d√©tect√©e")
            
            if patterns['unit_columns']:
                sheet_score += 15
                analysis['dpgf_compatibility']['detected_elements'].append(f"Colonnes d'unit√© ({len(patterns['unit_columns'])})")
            else:
                analysis['dpgf_compatibility']['missing_elements'].append("Aucune colonne d'unit√© d√©tect√©e")
            
            if patterns['structure_analysis']['potential_element_rows']:
                element_count = len(patterns['structure_analysis']['potential_element_rows'])
                if element_count >= 10:
                    sheet_score += 20
                elif element_count >= 5:
                    sheet_score += 10
                else:
                    sheet_score += 5
                analysis['dpgf_compatibility']['detected_elements'].append(f"√âl√©ments potentiels ({element_count})")
            else:
                analysis['dpgf_compatibility']['missing_elements'].append("Aucun √©l√©ment d√©tect√©")
            
            total_score = max(total_score, sheet_score)
        
        analysis['dpgf_compatibility']['score'] = total_score / max_score
        
        # G√©n√©rer des raisons pour le score
        if analysis['dpgf_compatibility']['score'] >= 0.8:
            analysis['dpgf_compatibility']['reasons'].append("Structure DPGF bien d√©finie")
        elif analysis['dpgf_compatibility']['score'] >= 0.5:
            analysis['dpgf_compatibility']['reasons'].append("Structure DPGF partielle")
        else:
            analysis['dpgf_compatibility']['reasons'].append("Structure DPGF faible ou absente")
        
        return analysis
    
    def generate_recommendations(self, analysis: Dict) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur l'analyse"""
        recommendations = []
        
        score = analysis['dpgf_compatibility']['score']
        missing = analysis['dpgf_compatibility']['missing_elements']
        
        if score < 0.3:
            recommendations.append("üö® Fichier probablement NON-DPGF - V√©rifier l'identification automatique")
            recommendations.append("üìã Examiner manuellement le contenu du fichier")
        
        if "Aucun lot d√©tect√©" in missing:
            recommendations.append("üîç Ajouter une ligne de lot explicite (ex: 'LOT 1 - Description')")
            recommendations.append("‚öôÔ∏è V√©rifier les mots-cl√©s de d√©tection des lots")
        
        if "Aucune section d√©tect√©e" in missing:
            recommendations.append("üìÇ Structurer le fichier avec des sections/chapitres")
            recommendations.append("üè∑Ô∏è Utiliser des mots-cl√©s comme 'Chapitre', 'Section', 'Poste'")
        
        if "Aucune colonne de prix d√©tect√©e" in missing:
            recommendations.append("üí∞ Ajouter une colonne 'Prix Unitaire' ou 'P.U.'")
            recommendations.append("üìä V√©rifier que les prix sont dans des colonnes d√©di√©es")
        
        if "Aucune colonne d'unit√© d√©tect√©e" in missing:
            recommendations.append("üìè Ajouter une colonne 'Unit√©' avec les unit√©s de mesure")
            recommendations.append("üî§ Utiliser des unit√©s standard (m¬≤, ml, kg, ens, etc.)")
        
        if "Aucun √©l√©ment d√©tect√©" in missing:
            recommendations.append("üìù V√©rifier que chaque ligne d'√©l√©ment a une d√©signation et un prix")
            recommendations.append("üî¢ S'assurer que les valeurs num√©riques sont bien format√©es")
        
        # Recommandations sp√©cifiques selon le score
        if 0.3 <= score < 0.6:
            recommendations.append("üîß Fichier partiellement compatible - Am√©liorer la structure")
            recommendations.append("üìö Consulter un exemple de DPGF type pour la structure")
        
        elif score >= 0.6:
            recommendations.append("‚úÖ Structure DPGF d√©tect√©e - V√©rifier les d√©tails de l'import")
            recommendations.append("üêõ Utiliser --debug-import pour voir les logs d√©taill√©s")
        
        return recommendations
    
    def save_analysis(self, output_file: str = None) -> str:
        """Sauvegarde l'analyse compl√®te"""
        analysis = self.analyze_file_structure()
        recommendations = self.generate_recommendations(analysis)
        
        full_analysis = {
            'metadata': {
                'analyzed_at': datetime.now().isoformat(),
                'file_path': str(self.file_path),
                'analyzer_version': '1.0'
            },
            'analysis': analysis,
            'recommendations': recommendations
        }
        
        if not output_file:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_name = "".join(c for c in self.file_path.stem if c.isalnum() or c in (' ', '-', '_'))[:30]
            output_file = f"analysis_{safe_name}_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(full_analysis, f, indent=2, ensure_ascii=False)
        
        return output_file
    
    def print_summary(self):
        """Affiche un r√©sum√© de l'analyse"""
        analysis = self.analyze_file_structure()
        recommendations = self.generate_recommendations(analysis)
        
        print("üîç ANALYSE D√âTAILL√âE DU FICHIER DPGF")
        print("=" * 60)
        print(f"üìÑ Fichier: {analysis['file_info']['name']}")
        print(f"üìä Taille: {analysis['file_info']['size']:,} octets")
        print(f"üìã Feuilles: {analysis['file_info']['sheets_count']}")
        print()
        
        # Score de compatibilit√©
        score = analysis['dpgf_compatibility']['score']
        score_pct = score * 100
        
        if score >= 0.8:
            status = "üü¢ EXCELLENTE"
        elif score >= 0.6:
            status = "üü° BONNE"
        elif score >= 0.3:
            status = "üü† FAIBLE"
        else:
            status = "üî¥ TR√àS FAIBLE"
        
        print(f"üéØ COMPATIBILIT√â DPGF: {status} ({score_pct:.1f}%)")
        print()
        
        # √âl√©ments d√©tect√©s
        if analysis['dpgf_compatibility']['detected_elements']:
            print("‚úÖ √âL√âMENTS D√âTECT√âS:")
            for element in analysis['dpgf_compatibility']['detected_elements']:
                print(f"   ‚Ä¢ {element}")
            print()
        
        # √âl√©ments manquants
        if analysis['dpgf_compatibility']['missing_elements']:
            print("‚ùå √âL√âMENTS MANQUANTS:")
            for element in analysis['dpgf_compatibility']['missing_elements']:
                print(f"   ‚Ä¢ {element}")
            print()
        
        # Analyse par feuille
        print("üìä ANALYSE PAR FEUILLE:")
        for sheet_name, patterns in analysis['sheets_analysis'].items():
            print(f"   üìã {sheet_name}:")
            print(f"      ‚Ä¢ Lots: {len(patterns['lot_indicators'])}")
            print(f"      ‚Ä¢ Sections: {len(patterns['section_indicators'])}")
            print(f"      ‚Ä¢ Colonnes prix: {len(patterns['price_columns'])}")
            print(f"      ‚Ä¢ Colonnes unit√©: {len(patterns['unit_columns'])}")
            print(f"      ‚Ä¢ √âl√©ments potentiels: {len(patterns['structure_analysis']['potential_element_rows'])}")
        print()
        
        # Recommandations
        if recommendations:
            print("üí° RECOMMANDATIONS:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")
            print()
        
        print("=" * 60)
    
    def close(self):
        """Ferme le fichier"""
        if self.workbook:
            self.workbook.close()

def main():
    """Fonction principale"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Analyse d√©taill√©e d'un fichier DPGF")
    parser.add_argument('file_path', help='Chemin vers le fichier DPGF √† analyser')
    parser.add_argument('--save-analysis', action='store_true', 
                       help='Sauvegarder l\'analyse en JSON')
    parser.add_argument('--output-file', help='Fichier de sortie pour l\'analyse')
    
    args = parser.parse_args()
    
    try:
        analyzer = DPGFFileAnalyzer(args.file_path)
        
        if args.save_analysis:
            output_file = analyzer.save_analysis(args.output_file)
            print(f"üìÑ Analyse sauvegard√©e: {output_file}")
        else:
            analyzer.print_summary()
    
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return 1
    
    finally:
        if 'analyzer' in locals():
            analyzer.close()
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
